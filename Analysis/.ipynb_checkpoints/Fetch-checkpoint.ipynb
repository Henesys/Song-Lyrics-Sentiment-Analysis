{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6c0e73a",
   "metadata": {},
   "source": [
    "# Fetch Data + Clean Data + Define Functions for Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "996d2a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lyricsgenius as genius\n",
    "\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "from googletrans import Translator\n",
    "from google_trans_new import google_translator  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bb0ae0",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "- Creates Pandas DataFrame with information regarding an artist and their music.\n",
    "- \"search\" parameter refers to any search fields used to find information using the Genius API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f173de52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMusic(search, token):\n",
    "\n",
    "    geniusAPI = genius.Genius(token)\n",
    "    \n",
    "    # Fields:\n",
    "    titleL = []\n",
    "    albumL = []\n",
    "    artistL = []\n",
    "    yearL = []\n",
    "    lyricsL = []\n",
    "    \n",
    "    artist = geniusAPI.search_artist(search, sort = \"popularity\", include_features = False)\n",
    "    \n",
    "    songs = artist.songs\n",
    "    \n",
    "    for i in songs:\n",
    "        titleL.append(i.title)\n",
    "        # albumL.append(i.album)\n",
    "        artistL.append(i.artist)\n",
    "        # yearL.append(i.year)\n",
    "        lyricsL.append(i.lyrics)\n",
    "        \n",
    "    # Remove album, year from dataframe for now.\n",
    "    music = pd.DataFrame({\n",
    "        \"Title\" : titleL,\n",
    "        \"Artist\" : artistL,\n",
    "        \"Lyrics\" : lyricsL\n",
    "    })\n",
    "    \n",
    "    return music"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45040975",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "- Cleans/ fixes data by removing strings (e.g. []) and fixing any and all irregularities in the song lyrics.\n",
    "- Will need to look into improper grammar (e.g. \"ur\", \"ya\", \"xo\"). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa71847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixLyrics(music, l):\n",
    "    \n",
    "    # l -> music[lyrics]\n",
    "    \n",
    "    music[l] = music[l].str.lower()\n",
    "    \n",
    "    # Based on observations made in EDA, will potentially need to add more:\n",
    "    \n",
    "    # Punctuation\n",
    "    music[l] = music[l].str.replace(\"[\",\"\")\n",
    "    music[l] = music[l].str.replace(\"]\",\"\")\n",
    "    \n",
    "    music[l] = music[l].str.replace(\"(\",\"\")\n",
    "    music[l] = music[l].str.replace(\")\",\"\")\n",
    "    \n",
    "    music[l] = music[l].str.replace(\":\",\"\")\n",
    "    music[l] = music[l].str.replace('\"',\"\")\n",
    "    music[l] = music[l].str.replace(\"-\",\"\")\n",
    "    music[l] = music[l].str.replace(\"&\",\"\")\n",
    "    \n",
    "    music[l] = music[l].str.replace(\"\\n\", \" \")\n",
    "    \n",
    "    # Verse Uppercase -> No longer needed due to str.lower()\n",
    "    music[l] = music[l].str.replace(\"Verse 1\",\"\")\n",
    "    music[l] = music[l].str.replace(\"Verse 2\",\"\")\n",
    "    music[l] = music[l].str.replace(\"Verse 3\",\"\")\n",
    "    \n",
    "    # Verse Lowercase\n",
    "    music[l] = music[l].str.replace(\"verse 1\",\"\")\n",
    "    music[l] = music[l].str.replace(\"verse 2\",\"\")\n",
    "    music[l] = music[l].str.replace(\"verse 3\",\"\")\n",
    "    music[l] = music[l].str.replace(\"verse 4\",\"\")\n",
    "    \n",
    "    # Uppercase () -> No longer needed due to str.lower()\n",
    "    music[l] = music[l].str.replace(\"Refrain\",\"\")\n",
    "    music[l] = music[l].str.replace(\"Chorus\",\"\")\n",
    "    music[l] = music[l].str.replace(\"Bridge\",\"\")\n",
    "    music[l] = music[l].str.replace(\"Outro\",\"\")\n",
    "    music[l] = music[l].str.replace(\"Pre-Chorus\",\"\")\n",
    "    music[l] = music[l].str.replace(\"Spoken\",\"\")\n",
    "    music[l] = music[l].str.replace(\"Original\",\"\")\n",
    "    music[l] = music[l].str.replace(\"Translated\",\"\")\n",
    "    music[l] = music[l].str.replace(\"Hm\",\"\")\n",
    "    music[l] = music[l].str.replace(\"Intro\",\"\")\n",
    "    music[l] = music[l].str.replace(\"Feat.\",\"\")\n",
    "    music[l] = music[l].str.replace(\"Ft.\",\"\")\n",
    "    music[l] = music[l].str.replace(\"Post-Chorus\",\"\")\n",
    "    \n",
    "    # Lowercase ()\n",
    "    music[l] = music[l].str.replace(\"refrain\",\"\")\n",
    "    music[l] = music[l].str.replace(\"chorus\",\"\")\n",
    "    music[l] = music[l].str.replace(\"bridge\",\"\")\n",
    "    music[l] = music[l].str.replace(\"outro\",\"\")\n",
    "    music[l] = music[l].str.replace(\"pre-chorus\",\"\")\n",
    "    music[l] = music[l].str.replace(\"spoken\",\"\")\n",
    "    music[l] = music[l].str.replace(\"original\",\"\")\n",
    "    music[l] = music[l].str.replace(\"translated\",\"\")\n",
    "    music[l] = music[l].str.replace(\"hm\",\"\")\n",
    "    music[l] = music[l].str.replace(\"intro\",\"\")\n",
    "    music[l] = music[l].str.replace(\"feat.\",\"\")\n",
    "    music[l] = music[l].str.replace(\"ft.\",\"\")\n",
    "    music[l] = music[l].str.replace(\"post-chorus\",\"\")\n",
    "    \n",
    "    # Miscellaneous\n",
    "    music[l] = music[l].str.replace(\"URLCopyEmbedCopy\",\"\")\n",
    "    music[l] = music[l].str.replace(\"urlcopyembedcopy\",\"\")\n",
    "    \n",
    "    music[l] = music[l].str.replace(\"EmbedShare\",\"\")\n",
    "    music[l] = music[l].str.replace(\"embedshare\",\"\")\n",
    "    \n",
    "    music[l] = music[l].str.replace(\"6embedshare\",\"\")\n",
    "    music[l] = music[l].str.replace(\"1embedshare\",\"\")\n",
    "    \n",
    "    music[l] = music[l].str.replace(\"english\",\"\")\n",
    "    \n",
    "    music[l] = music[l].str.replace(\"fxxk wit\",\"\")\n",
    "    \n",
    "    # Name\n",
    "    music[l] = music[l].str.replace(\"Lee Hi\",\"\")\n",
    "    music[l] = music[l].str.replace(\"lee hi\",\"\")\n",
    "    \n",
    "    music[l] = music[l].str.replace(\"b.i\",\"\")\n",
    "    music[l] = music[l].str.replace(\"jennie\",\"\")\n",
    "    music[l] = music[l].str.replace(\"choi hyun suk\",\"\")\n",
    "    music[l] = music[l].str.replace(\"dok2\",\"\")\n",
    "    music[l] = music[l].str.replace(\"mino\",\"\")\n",
    "    music[l] = music[l].str.replace(\"tablo\",\"\")\n",
    "    \n",
    "    # Korean\n",
    "    music[l] = music[l].str.replace(\"korean\",\"\")\n",
    "    \n",
    "    music[l] = music[l].str.replace(\"이하이\",\"\")\n",
    "    \n",
    "    music[l] = music[l].str.replace(\"가사\",\"\")\n",
    "    music[l] = music[l].str.replace(\"피처링.\",\"\")\n",
    "    \n",
    "    music[l] = music[l].str.replace(\"김제니\",\"\")\n",
    "    music[l] = music[l].str.replace(\"최현석\",\"\")\n",
    "    music[l] = music[l].str.replace(\"윤미래\",\"\")\n",
    "    music[l] = music[l].str.replace(\"원슈타인\",\"\")\n",
    "    music[l] = music[l].str.replace(\"송민호\",\"\")\n",
    "    \n",
    "    return music   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583c0ab0",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "- https://www.nltk.org/api/nltk.tokenize.html\n",
    "- Normalisation of lyrics.\n",
    "- Removal of stopwords.\n",
    "- Lemmatisation of Word Parameters vs Stemming of Word Parameters.\n",
    "- https://stackoverflow.com/questions/1787110/what-is-the-difference-between-lemmatization-vs-stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e001f4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arabic',\n",
       " 'azerbaijani',\n",
       " 'bengali',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'greek',\n",
       " 'hungarian',\n",
       " 'indonesian',\n",
       " 'italian',\n",
       " 'kazakh',\n",
       " 'nepali',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'slovene',\n",
       " 'spanish',\n",
       " 'swedish',\n",
       " 'tajik',\n",
       " 'turkish']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fef2a10",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "- NLTK has no stopwords in the Korean language.\n",
    "- https://github.com/6/stopwords-json/blob/master/dist/ko.json\n",
    "- https://konlpy.org/en/latest/\n",
    "- https://www.lucypark.kr/courses/2015-ba/text-mining.html#python-packages-for-text-mining-and-nlp\n",
    "- https://github.com/konlpy/konlpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13b90a0",
   "metadata": {},
   "source": [
    "### Options:\n",
    "- Option 1- Translate all lyrics into English -> Proceed with text analysis.\n",
    "- Option 2- Use KoNLPy to analyse Korean lyrics separately alongside English lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01809668",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 1 column 377 (char 376)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-a49ecec4ccb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msentenceKR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"한국 노래 분석\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtranslateKR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentenceKR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang_tgt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"en\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranslateKR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\School\\Code\\Anaconda\\lib\\site-packages\\google_trans_new\\google_trans_new.py\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(self, text, lang_tgt, lang_src, pronounce)\u001b[0m\n\u001b[0;32m    186\u001b[0m                                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpronounce_src\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpronounce_tgt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m             \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConnectTimeout\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\School\\Code\\Anaconda\\lib\\site-packages\\google_trans_new\\google_trans_new.py\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(self, text, lang_tgt, lang_src, pronounce)\u001b[0m\n\u001b[0;32m    150\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m                         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdecoded_line\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m']'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m                         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m                         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m                         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\School\\Code\\Anaconda\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\School\\Code\\Anaconda\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Extra data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Extra data: line 1 column 377 (char 376)"
     ]
    }
   ],
   "source": [
    "translator = google_translator()\n",
    "\n",
    "sentenceKR = \"한국 노래 분석\"\n",
    "translateKR = translator.translate(sentenceKR, lang_tgt = \"en\") \n",
    "\n",
    "print(translateKR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec25567",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "- Define stopwords and punctuation.\n",
    "- Remove stopwords and punctuation.\n",
    "- Lemmatisation and normalisation of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45863685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwordLyrics(l):\n",
    "    \n",
    "    nltk.download('stopwords')\n",
    "\n",
    "    # \"Valid\" English:\n",
    "    stops = set(stopwords.words('english'))\n",
    "    \n",
    "    # \"Valid\" Punctuation:\n",
    "    punctuation = set(string.punctuation)\n",
    "    \n",
    "    # Lemmatisation:\n",
    "    lemmatise = WordNetLemmatizer()\n",
    "    \n",
    "    # Remove Stopwords\n",
    "    stopsRemove = \" \".join([i for i in l.split() if i not in stops]) \n",
    "    \n",
    "    # Remove Punctuation\n",
    "    punctuationRemove = \" \".join(j for j in stopsRemove if j not in punctuation)\n",
    "    \n",
    "    # Normalisation:\n",
    "    normalise = \" \".join(lemmatise.lemmatize(k) for k in punctuationRemove.split())\n",
    "    \n",
    "    return normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70122769",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
